---
title: "Data 621 - Homework 1"
author: "Shamecca Marshall"
date: "2024-02-23"
output: html_document
---


```{r}
library(tidyr)
library(tidyverse)
library(knitr)
library(kableExtra)
library(DT)
library(reshape2)
library(car) 
library(naniar) 
library(corrplot) 
library(e1071) 
library(caret) 
```


## Overview
  In this homework assignment, you will explore, analyze and model a data set containing approximately 2200records. Each record represents a professional baseball team from the years 1871 to 2006 inclusive. Each record
has the performance of the team for the given year, with all of the statistics adjusted to match the performance of
a 162 game season.
  Your objective is to build a multiple linear regression model on the training data to predict the number of wins
for the team. You can only use the variables given to you (or variables that you derive from the variables
provided). Below is a short description of the variables of interest in the data set:

```{r}
train <- read_csv('https://raw.githubusercontent.com/Meccamarshall/Data621/main/Homework1/moneyball-training-data.csv', col_names = TRUE)[,-1] 
eval <- read_csv('https://raw.githubusercontent.com/Meccamarshall/Data621/main/Homework1/moneyball-evaluation-data.csv',col_names=TRUE)[,-1] 
```

Renaming the column names to make them less complicated
```{r}
colnames(train) <- gsub("TEAM_", "", colnames(train))
colnames(eval) <- gsub("TEAM_", "", colnames(eval))
```

# Data Exploration
```{r}
summary(train)
summary(eval)
```

Viewing rows, columns, and variable types
When we glimpse at the data we noticed that the variables are numeric. There are also alot of NA within the data set. 
```{r}
glimpse(train)
glimpse(eval)
```

Viewing a sample of the data for both training and eval data sets
```{r}
head(train)
head(eval)
```

Showing the entire training and evaluation data sets
```{r}
DT::datatable(train, options = list(pagelength=4))
DT::datatable(eval, options = list(pagelength=4))
```

Find the standard deviation for both datasets
```{r}
apply(train,2,sd, na.rm=TRUE)
apply(eval,2,sd, na.rm=TRUE)
```

## Visualizing data
Box plots
```{r}
ggplot(data = melt(train), aes(x=variable, y=value)) + geom_boxplot(aes(color=variable)) + coord_flip() + labs(title="BoxPlot for all variables")
```

The box plots above indicate that a significant portion of the explanatory variables exhibit high variances. Additionally, there is notable misalignment between many of the medians and means, highlighting the influence of outliers.

Density Curves to find skewness in data
```{r}
ggplot(melt(train), aes(x=value))+
geom_density(fill = "#ffc8dd", color="#cdb4db") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())
```

In the density curves above, it's evident that the variables for batting, pitching home runs, and batting strikeouts exhibit a bimodal distribution. Conversely, TARGET_WINS and TEAM_BATTING_2B display mostly normal distributions. FIELDING_E, PITCHING_BB, PITCHING_H, and PITCHING_SO demonstrate the most skewed data distributions, with all skewed graphs being right-skewed except for BATTING_BB.

## Finding Correlations in data
```{r}
DT::datatable(cor(drop_na(train[,])), options = list(pagelength=4))
```
```{r}
train %>% cor(., use="pairwise.complete.obs", method = "pearson") %>% corrplot(.,method = "color", type= "upper", tl.col="black", diag=TRUE , number.cex = 0.5, addCoef.col = 'black', tl.srt=50, col=colorRampPalette(c("#9c89b8","#f0a6ca","#b8bedd"))(200))
```

The correlation for the above heatmap indicates strong positive associations primarily with BATTING_BB, BATTING_H, BATTING_2B, BATTING_HR, PITCHING_BB, PITCHING_HR, and PITCHING_H.

```{r}
train %>%
  gather(variable, value, -TARGET_WINS) %>%
  ggplot(., aes(value, TARGET_WINS)) + 
  geom_point(fill = "#a9def9", color="#a9def9") + 
  geom_smooth(method = "lm", se = FALSE, color = "#7b2cbf") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = "Wins")+
  labs(title="Relationship Between Predictions and TARGET_WINS")
``` 

The above data illustrates the distribution compared to linear regression. It's evident that PITCHING_H and PITCHING_SO exhibit significant heteroscedasticity, while BATTING_HBP is comparatively more homoscedastic.

# Data Preparation

## Missing Data
```{r}
# Checking for any missing values
sapply(train, function(x) sum(is.na(x)))
```

```{r}
vis_miss(train)
```

```{r}
gg_miss_var(train)+ labs(title="Summary of Missing Data Visual")
```

## Removing/Fixing missing values
```{r}
train %>% 
  gather(variable, value) %>%
  filter(is.na(value)) %>%
  group_by(variable) %>%
  tally() %>%
  mutate(percent = n / nrow(train) * 100) %>%
  mutate(percent = paste0(round(percent, ifelse(percent < 10, 1, 0)), "%")) %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling()
```

Since more than 90% of the data for the BATTING_HBP is missing, the variable has been removed from both train and eval data. 