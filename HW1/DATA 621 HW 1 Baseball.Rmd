---
title: "DATA 621 HW 1"
author: "Jian Quan Chen"
date: "2024-02-22"
output: html_document
---

# Introduction

In this assignment, we are given a baseball training and evaluation dataset. The data spans from 1871 to 2006, each row representing a baseball team's performance that year. The statistics were all adjusted to reflect a 162 game season. Our objective is to construct a multiple linear regression model of the training data to predict the number of wins for a team. 

# 1. Data Exploration

```{r}
library(tidyverse)
library(corrplot)
```

```{r}
df <- read_csv("https://raw.githubusercontent.com/LeJQC/DATA-621-Group-2/main/HW1/moneyball-training-data.csv", show_col_types = FALSE)
```

There are 2,276 rows and 17 columns in the dataset. The response variable is `TARGET_WINS` and the remaining 15 variables, with the exception of the `INDEX` column, are predictor variables. 
```{r}
glimpse(df)
```

```{r}
# Setting index column to index
rownames(df) <- df$INDEX
df$INDEX <- NULL

# Sumarry table
knitr::kable(summary(df))
```

We can see from the summary, that the mean of `TARGET_WINS` is 80.79, which is about half the games in a baseball season. There are also a couple of columns with NA values, specifically `TEAM_BATTING_HBP` has over 2000 missing values. 

Let's look at the distribution of the data.
```{r}
df_long <- df %>%
  pivot_longer(
    cols = everything(), 
    names_to = "variable",
    values_to = "value"
  )

df_long %>%
  ggplot(aes(value)) + 
  geom_density(fill = "blue") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = element_blank())
```

The `TARGET_WINS`, `TEAM_BATTING_2B`, `TEAM_BATTING_HBP`, and `TEAM_FIELDING_DP`  variables show a normal distribution. The `TEAM_BATTING_HR`, `TEAM_BATTING_SO`, and `TEAM_PITCHING_HR` variables show a bimodal distribution.

```{r}
df %>% 
  cor(use = "complete.obs") %>%
  corrplot(method = "color", tl.col = "black")
```

From this visual, wins seem to be most correlated with `TEAM_PITCHING_H`, `TEAM_PTICHING_BB`,`TEAM_BATTING_BB`, `TEAM_BATTING_2B`, and `TEAM_BATTING_H`.

```{r}
cor(df)
```

# 2. Data Preparation
Checking for missing values within the dataset by creating flags for every column
```{r}
# Loop through columns
for (col_name in names(df)) {
  missing <- is.na(df[[col_name]])
  output <- paste(col_name,"missing values?",any(missing))
  print(output)
}
```


Since the `TEAM_BATTING_HBP` variable was missing 2000 values, we will just remove this column from the dataset. The other columns that had missing values (`TEAM_BATTING_SO`, `TEAM_BASERUN_SB`, `TEAM_BASERUN_CS`, `TEAM_PITCHING_SO`, and `TEAM_FIELDING_DP`) will be replaced with the median value of that variable. 

```{r}
df <- df %>% select(-TEAM_BATTING_HBP)

na_variables <- c("TEAM_BATTING_SO", "TEAM_BASERUN_SB", "TEAM_BASERUN_CS", "TEAM_PITCHING_SO", "TEAM_FIELDING_DP")

for (col in na_variables) {
  median_value <- median(df[[col]], na.rm = TRUE)
  df[[col]][is.na(df[[col]])] <- median_value
}

summary(df)
```


Checking for any missing values within the dataset
```{r}
which(is.na(df))
 
# count total missing values 
print("Count of total missing values  ")
sum(is.na(df))
```

Now there is no more missing values within the dataset

## Buid Models

Lets build a multiple linear regression model with the response variable being TARGET_WINS ans the explanatory variables being TEAM_BATTING_H, TEAM_BATTING_BB, and TEAM_BATTING_2B this is because they had the higher correlation values to the TARGET_WINS variable. I omitted the intercept within the model because if the intercept in a regression model predicting baseball team wins is negative, it suggests that even when all independent variables are set to zero, the model predicts a negative number of wins. This negative prediction essentially indicates that the team is expected to have more losses than wins, which is not realistic or meaningful in the context of baseball. 
```{r}
##Fit the multiple linear regression model
model <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_BB + TEAM_BATTING_2B+0, data = df)

summary(model)
```
The coefficients obtained from our multiple linear regression model shed light on the relationship between specific baseball metrics and the number of wins. For instance, the coefficient for "TEAM_BATTING_H" (Base Hits by batters) is approximately 0.044, indicating that for each additional base hit, we expect around 0.044 more wins, holding other variables constant. Similarly, the coefficient for "TEAM_BATTING_BB" (Walks allowed) is approximately 0.034, suggesting that each additional walk allowed by the pitching team is associated with around 0.034 more wins.

However, the coefficient for "TEAM_BATTING_2B" (Doubles by batters) is approximately -0.003, which is statistically insignificant (p-value = 0.679). This suggests that the number of doubles by batters may not have a significant effect on wins. This finding may appear counterintuitive, as one might expect teams with more doubles to win more games.

Despite this inconsistency, the overall model demonstrates a strong ability to explain win variance, with an adjusted R-squared value of 0.9714. This indicates that the model accounts for a significant portion of the variability in wins based on the included variables. Therefore, it may be advisable to retain the model for further analysis and refinement.




